{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from litgpt import Config\n",
    "from litgpt.data import TextFiles\n",
    "from litgpt.pretrain import setup\n",
    "from litgpt.args import EvalArgs, TrainArgs\n",
    "\n",
    "# Define your custom model configuration\n",
    "class CustomConfig(Config):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            name=\"custom_model\",\n",
    "            n_layer=6,\n",
    "            n_head=6,\n",
    "            n_embd=384,\n",
    "            block_size=1024,\n",
    "            vocab_size=25005,  # Adjust this based on your tokenizer\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "# Set up the data module\n",
    "data_module = TextFiles(\n",
    "    train_data_path=Path(\"/content/drive/MyDrive/litgpt/input/train\"),\n",
    "    val_data_path=Path(\"/content/drive/MyDrive/litgpt/input/val\"),  # Optional, can be None\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Set up training arguments\n",
    "train_args = TrainArgs(\n",
    "    save_interval=1000,\n",
    "    log_interval=1,\n",
    "    global_batch_size=32,\n",
    "    micro_batch_size=4,\n",
    "    max_tokens=int(1e9),  # Adjust based on your dataset size and available compute\n",
    "    max_norm=1.0,\n",
    "    min_lr=4e-5,\n",
    "    lr_warmup_steps=700,\n",
    "    max_steps=19073,\n",
    "    tie_embeddings=False,\n",
    ")\n",
    "\n",
    "# Set up evaluation arguments\n",
    "eval_args = EvalArgs(interval=1000, max_iters=100)\n",
    "\n",
    "# Run the pretraining setup\n",
    "setup(\n",
    "    model_name=\"custom_model\",\n",
    "    model_config=CustomConfig(),\n",
    "    data=data_module,\n",
    "    train=train_args,\n",
    "    eval=eval_args,\n",
    "    out_dir=Path(\"./out/pretrain_custom\"),\n",
    "    precision=\"bf16-mixed\",  # Adjust based on your hardware capabilities\n",
    "    devices=\"auto\",\n",
    "    tokenizer_dir=Path(\"/path/to/your/tokenizer/directory\"),  # If you have a custom tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
